<!DOCTYPE html>
<html>
<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body background-color = "black">
    <style>
.buttonS{
    position:absolute;
    top: 80%;
    left: 90%;
    transform: translateY(-50%) translateX(-50%);
    width: 140px;
    height: 140px;
    box-shadow: none;
    background: #ffa500;
    border-radius: 200%;
    font-family: serif;
    color: white;
    background: transparent;
    cursor: pointer;
    text-align: center;
    background: rgba(300,300,300,0.5);
    font-size: 20px;
}
.buttonS:active{
    box-shadow: 0px 5px 8px 5px #87cefa;
    background: linear-gradient(#87cefa, #afeeee);
    border-bottom:none;
}
.midashi{
    position:absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%,-550%);
    text-shadow: 0 0 15px #666;
    font-family: serif;
    color: azure;
}
.midashi2{
    position:absolute;
    top: 50%;
    left: 40%;
    transform: translate(-15%,-480%);
    text-shadow: 0 0 15px #666;
    font-family: serif;
    color: azure;
}
#video-area{
    position: fixed;
    z-index: -1;/*最背面に設定*/
    top: 0;
    right:0;
    left:0;
    bottom:0;
    overflow: hidden;
}

#video {
    /*天地中央配置*/
    position: absolute;
    z-index: -1;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    /*縦横幅指定*/
    width: 177.77777778vh; /* 16:9 の幅→16 ÷ 9＝ 177.77% */
    height: 56.25vw; /* 16:9の幅 → 9 ÷ 16 = 56.25% */
    min-height: 100%;
    min-width: 100%;
}
        
@keyframes fadeIn { /*animation-nameで設定した値を書く*/
    0% {opacity: 0} /*アニメーション開始時は不透明度0%*/
    100% {opacity: 1} /*アニメーション終了時は不透明度100%*/
}
</style>
    <div id="video-area">
    <video id="video" poster="./img/Start.png" webkit-playsinline playsinline muted autoplay loop>
    <source src="./img/Start.mp4" type="video/mp4">
    </video>
    </div>
    <h1 class="midashi" id="midashi1"> Teachable Machine</h1>
    <h1 class="midashi2" id="midashi2">Ryouiki-Tenkai Model</h1>
<button type="button" onclick="back()" class="buttonS">suspend ryouiki-tenkai</button>
<ul id="info"></ul>
<div id="label-container"></div>
<script src="./tf.min.js"></script>
<script src="./speech-commands.min.js"></script>

<script type="text/javascript" defer>
    // more documentation available at
    // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://KoyanagiT.github.io/KnowInfo/my_model/";

    async function createModel() {
        const checkpointURL = URL + "model.json"; // model topology
        const metadataURL = URL + "metadata.json"; // model metadata

        const recognizer = speechCommands.create(
            "BROWSER_FFT", // fourier transform type, not useful to change
            undefined, // speech commands vocabulary feature, not useful for your models
            checkpointURL,
            metadataURL);

        // check that model and metadata are loaded via HTTPS requests.
        await recognizer.ensureModelLoaded();

        return recognizer;
    }

    async function init() {
        const recognizer = await createModel();
        const classLabels = recognizer.wordLabels(); // get class labels
        const midashi1Container = document.getElementById("midashi1");
        const midashi2Container = document.getElementById("midashi2");
        
        var query = location.search;
        var value = query.split('=');
        console.log(decodeURIComponent(value[1]));
        
        //<ul id = "info"></ul>の中を一度削除する
        document.getElementById('info').innerHTML = "";

		var text1 = document.createElement("p");
        text1.innerHTML = decodeURIComponent(value[1]);
        document.getElementById('info').appendChild(text1);
        
        tag = document.getElementById("video");
        switch(decodeURIComponent(value[1])){
            case "kan-gou-an-ei-tei":
                tag.src = "./img/kangouCharge.mp4";
                midashi1Container.innerHTML = "kan-gou-an-ei-tei";
                midashi2Container.innerHTML = "is Ready to activate...";
                break;
            case "gai-kan-techi-sen":
                tag.src = "./img/gaikanCharge.mp4";
                midashi1Container.innerHTML = "gai-kan-techi-sen";
                midashi2Container.innerHTML = "is Ready to activate...";
                break;
            case "hu-ku-ma-mizushi":
                tag.src = "./img/hukumaCharge.mp4";
                midashi1Container.innerHTML = "hu-ku-ma-mizushi";
                midashi2Container.innerHTML = "is Ready to activate...";
                break;
        } 
           
        //const content = element.innerHTML;
        //element.innerHTML = "<div>"+decodeURIComponent(value[1])+"</div>";
        
        // listen() takes two arguments:
        // 1. A callback function that is invoked anytime a word is recognized.
        // 2. A configuration object with adjustable fields
        recognizer.listen(result => {
            const scores = result.scores; // probability of prediction for each class
            // render the probability scores per class

            var detect = "noise";
            for (let i = 0; i < classLabels.length; i++) {
                result.scores[i].toFixed(2);
                //ルーモス検知
                if(result.scores[i].toFixed(2) > 0.96 && classLabels[i] !="バックグラウンド ノイズ"){
                    detect = classLabels[i];
                }
            }
            if(detect == "hikari-yo"){
                tag = document.getElementById("video");
                tag.src = "./img/hikariyo.mp4";
                setTimeout(function(){
                    window.location.href = "https://koyanagit.github.io/Ryouiki_tenkai/";
                }, 700);
            }
            switch(decodeURIComponent(value[1])){
                case "kan-gou-an-ei-tei":
                    if(detect == "kagou"){
                        tag.src = "./img/kangou.mp4";
                    }
                    break;
                case "gai-kan-techi-sen":
                    if(detect == "gaikan"){
                        tag.src = "./img/hukuma.mp4";
                    }
                    break;
                case "hu-ku-ma-mizushi":
                    if(detect == "hukuma"){
                        tag.src = "./img/gaikan.mp4";
                    }
                    break;
            }
        }, {
            includeSpectrogram: true, // in case listen should return result.spectrogram
            probabilityThreshold: 0.75,
            invokeCallbackOnNoiseAndUnknown: true,
            overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
        });

        // Stop the recognition in 5 seconds.
        // setTimeout(() => recognizer.stopListening(), 5000);
    }
    
    function back() {
        window.location.href = "https://koyanagit.github.io/Ryouiki_tenkai/"
    }
    
    init();
</script>
</body>
</html>
